install.packages('blogdown')
blogdown::install_hugo()
blogdown::update_hugo()
blogdown::update_hugo()
anova(m1)
blogdown::new_site()
?blogdown::new_site()
blogdown::new_site(dir = ".\firstblog")
blogdown::new_site(dir = "~firstblog")
blogdown::new_site(dir = ".", theme = "kimcc/hugo-theme-noteworthy")
blogdown::new_site(dir = ".", theme = "kimcc/hugo-theme-noteworthy")
blogdown::new_site(dir = ~tryblog, theme = "kimcc/hugo-theme-noteworthy")
blogdown::new_site(dir = "~tryblog", theme = "kimcc/hugo-theme-noteworthy")
- ((7840/(33))/(17190/(35)))
1 - ((7840/(33))/(17190/(35)))
7840/33
9350/2
4675/237.5758
model1<-lm(Price2014~distance, data=RailsTrails)
summary(model1)
model1<-lm(Price2014~distance, data=RailsTrails)
summary(model1)
#This brings in the dataset we need from the Stat2Data package
data("RailsTrails")
# Some customization to format the file, bring in the data you need.  Do not alter.
# knitr settings to control how R chunks work and how the pdf is compiled when knit.
require(knitr)
opts_chunk$set(
tidy=TRUE,                     # display code as typed
size="small",                   # slightly smaller font for code
tidy.opts=list(width.cutoff=65), # wrap text and long comments
fig.width=7, fig.height=5           #figure size
)
#Requiring Stat2Data package for the data
# If you're working locally on your computer, you will need to install some of these packages--see code below.
#install.packages(Stat2Data)
require(Stat2Data)
require(mosaic)
require(tidyverse)
#This brings in the dataset we need from the Stat2Data package
data("RailsTrails")
model1<-lm(Price2014~distance, data=RailsTrails)
summary(model1)
model1<-lm(Price2014~Distance, data=RailsTrails)
summary(model1)
model1<-lm(Price2014~Distance + Bedrooms, data=RailsTrails)
summary(model1)
1.96*9.165
-40.006 + 17.9634
-40.006 - 17.9634
146.859 - 40.006(2000) + 58.712(3)
146.859 - (40.006*(2000)) + (58.712*(3))
146.859 - (40.006*(2)) + (58.712*(3))
146.859 - (40.006*(2)) + (58.712*(4))
301.695 - 242.983
146.859 - (40.006*(1.5)) + (58.712*(2))
146.859 - (40.006*(2.5)) + (58.712*(2))
164,268-204,274
164268-204274
164.268 - 204.274
11.8 + (1.12*(76)) + (0.0342*(200)) - (1.09*(7))
blogdown:::new_post_addin()
#This brings in the dataset we need from the Stat2Data package
data("Speed")
# Some customization to format the file, bring in the data you need.  Do not alter.
# knitr settings to control how R chunks work and how the pdf is compiled when knit.
require(knitr)
opts_chunk$set(
tidy=TRUE,                     # display code as typed
size="small",                   # slightly smaller font for code
tidy.opts=list(width.cutoff=65), # wrap text and long comments
fig.width=7, fig.height=5           #figure size
)
#Requiring Stat2Data package for the data
# If you're working locally on your computer, you will need to install some of these packages--see code below.
#install.packages(Stat2Data)
require(Stat2Data)
require(mosaic)
require(tidyverse)
#This brings in the dataset we need from the Stat2Data package
data("Speed")
glimpse(Speed)
model1<-lm(Year~FatalityRate, data = "Speed")
summary(model1)
model1<-lm(Year~FatalityRate, data = Speed)
summary(model1)
model1 <- lm(FatalityRate ~ Year, data = Speed)
summary(model1)
plot(model1, which=c(1))
model2 <- lm(FatalityRate ~ Year + StateControl + Year*StateControl, data = Speed)
summary(model2)
require(mosaic)
require(tidyverse)
require(magrittr)
data("Gestation")
Gestation<-Gestation %>% filter(!is.na(smoke), !is.na(wt))
m_quant<-lm(wt~smoke, data=Gestation)
summary(m_quant)
Gestation<-Gestation %>%
mutate(smoke_factor=as.factor(smoke))
m_cat1<-lm(wt~smoke_factor, data=Gestation)
summary(m_cat1)
Gestation<-Gestation %>%
mutate(smoke_cat=as.factor(if_else(smoke==0,"never smoker",
if_else(smoke==1,"current smoker",
if_else(smoke==2,"pre-pregnancy smoker",
if_else(smoke==3,"other former smoker","NA"))))
)
)
tally(~smoke_cat, data=Gestation)
smoke_factor_labels<-lm(wt~I(smoke_cat), data=Gestation)
summary(smoke_factor_labels)
?tally
anova(model2)
anova(model1)
anova(wt4cat_temp)
anova(model1, model2)
?I
anova(model2)
anova(model1)
anova(model2)
model1 <- lm(FatalityRate ~ Year, data = Speed)
summary(model1)
model2 <- lm(FatalityRate ~ Year + StateControl + Year*StateControl, data = Speed)
summary(model2)
anova(model1)
anova(model2)
anova(model1, model2)
anova(model1, model2)
model3 <- lm(FatalityRate ~ Year + StateControl, data = Speed)
anova(model3)
anova(model2)
anova(model3, model2)
anova(model2)
summary(model2)
model1 <- lm(Calories ~ Sugar + Fiber, data = Cereal)
summary(model1)
m1stdResid <- Cereal %>%
mutate(R_raw=model1$residuals, R_stnd=rstandard(model1), R_fit=model1$fitted)
qplot(x=R_fit, y=R_stnd, data=m1stdResid) +
geom_hline(yintercept=c(-3, 3), color="red", linetype=2) +
geom_hline(yintercept=c(-2, 2), color="black", linetype=2) +
geom_hline(yintercept=0, color="grey", linetype=3) +
scale_y_continuous(name="Standardized Residuals", breaks=seq(-3.5,3.5,0.5))
# Some customization to format the file, bring in the data you need.  Do not alter.
# knitr settings to control how R chunks work and how the pdf is compiled when knit.
require(knitr)
opts_chunk$set(
tidy=TRUE,                     # display code as typed
size="small",                   # slightly smaller font for code
tidy.opts=list(width.cutoff=65), # wrap text and long comments
fig.width=7, fig.height=5           #figure size
)
#Requiring Stat2Data package for the data
# If you're working locally on your computer, you will need to install some of these packages--see code below.
#install.packages(Stat2Data)
require(Stat2Data)
require(mosaic)
require(tidyverse)
#This brings in the dataset we need from the Stat2Data package
data("Cereal")
data("Perch")
model1 <- lm(Calories ~ Sugar + Fiber, data = Cereal)
summary(model1)
m1stdResid <- Cereal %>%
mutate(R_raw=model1$residuals, R_stnd=rstandard(model1), R_fit=model1$fitted)
qplot(x=R_fit, y=R_stnd, data=m1stdResid) +
geom_hline(yintercept=c(-3, 3), color="red", linetype=2) +
geom_hline(yintercept=c(-2, 2), color="black", linetype=2) +
geom_hline(yintercept=0, color="grey", linetype=3) +
scale_y_continuous(name="Standardized Residuals", breaks=seq(-3.5,3.5,0.5))
# Summarize multiple regression model for cereal calories ~ sugar and fiber
model1 <- lm(Calories ~ Sugar + Fiber, data = Cereal)
summary(model1)
# Plot standardized residuals
m1stdResid <- Cereal %>%
mutate(R_raw=model1$residuals, R_stnd=rstandard(model1), R_fit=model1$fitted)
qplot(x=R_fit, y=R_stnd, data=m1stdResid) +
geom_hline(yintercept=c(-3, 3), color="red", linetype=2) +
geom_hline(yintercept=c(-2, 2), color="black", linetype=2) +
geom_hline(yintercept=0, color="grey", linetype=3) +
scale_y_continuous(name="Standardized Residuals", breaks=seq(-3.5,3.5,0.5))
# Summarize standardized residuals
m1_diag<-ls.diag(m1stdResid) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
resid<-m1stdResid$resid
stnd_res<-m1stdResid$std.res
fitted<-m1stdResid$fitted
cereal_resid<-cbind(Cereal,resid, stnd_res, fitted)
cereal_resid%>%
mutate(m_out_stnd=ifelse(abs(stnd_res)>2,"y","n"),
s_out_stnd=ifelse(abs(stnd_res)>3,"y","n")) %>%
filter(m_out_stnd=="y" | m_out_stud=="y")
View(m1stdResid)
m1_diag<-ls.diag(m1stdResid) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
ls.diag?
hsajkd
?ls.diag
m1_diag<-ls.diag(as.numeric(m1stdResid)) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
resid<-m1stdResid$resid
stnd_res<-m1stdResid$std.res
fitted<-m1stdResid$fitted
cereal_resid<-cbind(Cereal,resid, stnd_res, fitted)
cereal_resid%>%
mutate(m_out_stnd=ifelse(abs(stnd_res)>2,"y","n"),
s_out_stnd=ifelse(abs(stnd_res)>3,"y","n")) %>%
filter(m_out_stnd=="y")
cereal_resid<-cbind(Cereal,resid, stnd_res, stud_res, fitted)
# Summarize standardized residuals
m1_diag<-ls.diag(model1) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
View(m1_diag)
m1_diag
# Summarize multiple regression model for cereal calories ~ sugar and fiber
model1 <- lm(Calories ~ Sugar + Fiber, data = Cereal)
summary(model1)
# Plot standardized residuals
m1stdResid <- Cereal %>%
mutate(R_raw=model1$residuals, R_stnd=rstandard(model1), R_fit=model1$fitted)
qplot(x=R_fit, y=R_stnd, data=m1stdResid) +
geom_hline(yintercept=c(-3, 3), color="red", linetype=2) +
geom_hline(yintercept=c(-2, 2), color="black", linetype=2) +
geom_hline(yintercept=0, color="grey", linetype=3) +
scale_y_continuous(name="Standardized Residuals", breaks=seq(-3.5,3.5,0.5))
PB_diag<-ls.diag(m1stdResid) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
knitr::opts_chunk$set(echo = FALSE)
require(Stat2Data)
require(tidyverse)
require(magrittr)
data(LongJumpOlympics) #dataset names that are bolded in your book are in the Stat2Data package!
qplot(y=Gold, x=Year, data=LongJumpOlympics)+geom_smooth(method="lm", se=FALSE)
LongJump<-lm(Gold~Year, data=LongJumpOlympics)
summary(LongJump)
plot(LongJump, which=1)
LJResids<- LongJumpOlympics %>%
mutate(R_raw=LongJump$residuals, R_stnd=rstandard(LongJump), R_fit=LongJump$fitted)
qplot(x=R_fit, y=R_stnd, data=LJResids) +
geom_hline(yintercept=c(-3, 3), color="red", linetype=2) +
geom_hline(yintercept=c(-2, 2), color="black", linetype=2) +
geom_hline(yintercept=0, color="grey", linetype=3) +
scale_y_continuous(name="Standardized Residuals", breaks=seq(-3.5,3.5,0.5))
data(PalmBeach)
PB<-lm(Buchanan~Bush, data=PalmBeach)
beta0_PB <- PB$coeff[1]
slope_PB <- PB$coeff[2]
PalmBeach_1 <- PalmBeach %>%
filter(County!="PALM BEACH")
PB_1<-lm(Buchanan~Bush, data=PalmBeach_1)
beta0_noPB <- PB_1$coeff[1]
slope_noPB <- PB_1$coeff[2]
PalmBeach_2 <- PalmBeach %>%
filter(County!="DADE")
PB_2<-lm(Buchanan~Bush, data=PalmBeach_2)
beta0_noDADE <- PB_2$coeff[1]
slope_noDADE <- PB_2$coeff[2]
OnlyPB <- PalmBeach %>%
filter(County=="PALM BEACH")
OnlyDADE <- PalmBeach %>%
filter(County=="DADE")
ggplot(PalmBeach, aes(x = Bush, y = Buchanan)) + geom_point() +
geom_point(data=OnlyPB, aes(x=Bush, y=Buchanan), colour="red", size=2) +
geom_point(data=OnlyDADE, aes(x=Bush, y=Buchanan), colour="blue", size=2) +
labs( x= 'Bush', y='Buchanan') +
geom_abline(intercept = beta0_PB , slope = slope_PB)
# + geom_abline(intercept = beta0_noPB , slope = slope_noPB, colour = "red") +
#geom_abline(intercept = beta0_noDADE , slope = slope_noDADE, colour = "blue")
ggplot(PalmBeach, aes(x = Bush, y = Buchanan)) + geom_point() +
ggtitle("With (Black) and Without Palm Beach County (Red)") +
geom_point(data=OnlyPB, aes(x=Bush, y=Buchanan), colour="red", fill="white", size=2, shape=21) +
# geom_point(data=OnlyDADE, aes(x=Bush, y=Buchanan), colour="blue", fill="white", size=2) +
labs( x= 'Bush', y='Buchanan') +
geom_abline(intercept = beta0_PB , slope = slope_PB) +
geom_abline(intercept = beta0_noPB , slope = slope_noPB, colour = "red")
# + geom_abline(intercept = beta0_noDADE , slope = slope_noDADE, colour = "blue")
ggplot(PalmBeach, aes(x = Bush, y = Buchanan)) + geom_point() +
ggtitle("With (Black) and Without Palm Beach County (Red) and Dade County (Blue)") +
#geom_point(data=OnlyPB, aes(x=Bush, y=Buchanan), colour="red", fill="white", size=2, shape=21) +
geom_point(data=OnlyDADE, aes(x=Bush, y=Buchanan), colour="blue", fill="white", size=2, shape=21) +
labs( x= 'Bush', y='Buchanan') +
geom_abline(intercept = beta0_PB , slope = slope_PB) +
#geom_abline(intercept = beta0_noPB , slope = slope_noPB, colour = "red") +
geom_abline(intercept = beta0_noDADE , slope = slope_noDADE, colour = "blue")
PalmBeach_3 <- PalmBeach %>%
filter(County!="PALM BEACH" & County!="DADE")
PB_3<-lm(Buchanan~Bush, data=PalmBeach_3)
beta0_neither <- PB_3$coeff[1]
slope_neither <- PB_3$coeff[2]
ggplot(PalmBeach, aes(x = Bush, y = Buchanan)) + geom_point() +
ggtitle("With (Black) and Without either Palm Beach County or Dade County (Dashed)") +
geom_point(data=OnlyPB, aes(x=Bush, y=Buchanan), colour="grey", fill="white", size=2, shape=21) +
geom_point(data=OnlyDADE, aes(x=Bush, y=Buchanan), colour="grey", fill="white", size=2, shape=21) +
labs( x= 'Bush', y='Buchanan') +
geom_abline(intercept = beta0_PB , slope = slope_PB) +
#geom_abline(intercept = beta0_noPB , slope = slope_noPB, colour = "red") +
geom_abline(intercept = beta0_neither , slope = slope_neither, linetype="dashed")
data("PalmBeach") #bringing in the data
PB_lm<-lm(Buchanan~Bush, data=PalmBeach) #fitting the regression model
m1_diag<-ls.diag(model1) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
h_i<-m1_diag$hat
county_lev<-cbind(Cereal,h_i)
m1_diag<-ls.diag(model1) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
h_i<-m1_diag$hat
cereal_lev<-cbind(Cereal,h_i)
data("PalmBeach") #bringing in the data
PB_lm<-lm(Buchanan~Bush, data=PalmBeach) #fitting the regression model
PB_diag<-ls.diag(PB_lm) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
h_i<-PB_diag$hat
county_lev<-cbind(PalmBeach,h_i)
ggplot(PalmBeach, aes(x = Bush, y = Buchanan)) + geom_point() +
ggtitle("Palm Beach County (Red) or Dade County (Blue)") +
geom_point(data=OnlyPB, aes(x=Bush, y=Buchanan), colour="red", size=2) +
geom_point(data=OnlyDADE, aes(x=Bush, y=Buchanan), colour="blue", size=2) +
labs( x= 'Bush', y='Buchanan') +
geom_abline(intercept = beta0_PB , slope = slope_PB) +
geom_vline(xintercept=43355.76, color="yellow")
m1_diag<-ls.diag(model1) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
h_i<-m1_diag$hat
cereal_lev<-cbind(Cereal,h_i)
k<-2 #MR - 2 slope terms
n<-36 #36 cereals
cereal_lev %>%
mutate(m_unusual=ifelse(h_i>(2*(k+1)/n),"y","n"),
v_unusual=ifelse(h_i>(3*(k+1)/n),"y","n"),
typ_lev=(k+1)/n,
pct_typ_lev=h_i/typ_lev) %>%
filter(m_unusual=="y")
cooks<-m1_diag$cooks
cereal_cook<-cbind(Cereal,cooks)
cereal_cook%>%
mutate(mod_inf=ifelse(cooks>0.5,"y","n"),
ver_inf=ifelse(cooks>1,"y","n")) %>%
filter(mod_inf=="y")
plot(model1, which=5)
m1_diag<-ls.diag(model1) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
View(m1_diag)
m1_diag
m1_diag<-ls.diag(model1) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
resid<-model1$resid
stnd_res<-m1_diag$std.res
stud_res<-m1_diag$stud.res
fitted<-model1$fitted
county_resid<-cbind(PalmBeach,resid, stnd_res, stud_res, fitted)
county_resid%>%
mutate(m_out_stnd=ifelse(abs(stnd_res)>2,"y","n"),
s_out_stnd=ifelse(abs(stnd_res)>3,"y","n"),
m_out_stud=ifelse(abs(stud_res)>2,"y","n"),
s_out_stud=ifelse(abs(stud_res)>3,"y","n")) %>%
filter(m_out_stnd=="y" | m_out_stud=="y")
m1_diag<-ls.diag(model1) #using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
resid<-model1$resid
stnd_res<-m1_diag$std.res
stud_res<-m1_diag$stud.res
fitted<-model1$fitted
cereal_resid<-cbind(Cereal,resid, stnd_res, stud_res, fitted)
cereal_resid%>%
mutate(m_out_stnd=ifelse(abs(stnd_res)>2,"y","n"),
s_out_stnd=ifelse(abs(stnd_res)>3,"y","n"),
m_out_stud=ifelse(abs(stud_res)>2,"y","n"),
s_out_stud=ifelse(abs(stud_res)>3,"y","n")) %>%
filter(m_out_stnd=="y" | m_out_stud=="y")
# Summarize multiple regression model for cereal calories ~ sugar and fiber
model1 <- lm(Calories ~ Sugar + Fiber, data = Cereal)
summary(model1)
# Plot standardized residuals
m1stdResid <- Cereal %>%
mutate(R_raw=model1$residuals, R_stnd=rstandard(model1), R_fit=model1$fitted)
qplot(x=R_fit, y=R_stnd, data=m1stdResid) +
geom_hline(yintercept=c(-3, 3), color="red", linetype=2) +
geom_hline(yintercept=c(-2, 2), color="black", linetype=2) +
geom_hline(yintercept=0, color="grey", linetype=3) +
scale_y_continuous(name="Standardized Residuals", breaks=seq(-3.5,3.5,0.5))
#using the least squares diagnostic (ls.diag) function to calculate the leverage and standardized residuals
m1_diag <- ls.diag(model1)
resid <- model1$resid
stnd_res <- m1_diag$std.res
stud_res <- m1_diag$stud.res
fitted <- model1$fitted
cereal_resid <- cbind(Cereal,resid, stnd_res, stud_res, fitted)
cereal_resid %>%
mutate(m_out_stnd=ifelse(abs(stnd_res)>2,"y","n"),
s_out_stnd=ifelse(abs(stnd_res)>3,"y","n"),
m_out_stud=ifelse(abs(stud_res)>2,"y","n"),
s_out_stud=ifelse(abs(stud_res)>3,"y","n")) %>%
filter(m_out_stnd=="y" | m_out_stud=="y")
h_i<-m1_diag$hat
cereal_lev<-cbind(Cereal,h_i)
k<-2 #MR - 2 slope terms
n<-36 #36 cereals
cereal_lev %>%
mutate(m_unusual=ifelse(h_i>(2*(k+1)/n),"y","n"),
v_unusual=ifelse(h_i>(3*(k+1)/n),"y","n"),
typ_lev=(k+1)/n,
pct_typ_lev=h_i/typ_lev) %>%
filter(m_unusual=="y")
cooks<-m1_diag$cooks
cereal_cook<-cbind(Cereal,cooks)
cereal_cook%>%
mutate(mod_inf=ifelse(cooks>0.5,"y","n"),
ver_inf=ifelse(cooks>1,"y","n")) %>%
filter(mod_inf=="y")
plot(model1, which=5)
knitr::opts_chunk$set(echo = TRUE)
require(Stat2Data)
require(mosaic)
require(magrittr)
require(tidyverse)
data("FirstYearGPA")
set.seed(8675309)
SATM_orig<-lm(GPA~SATM*HSGPA, data=FirstYearGPA)
summary(SATM_orig)
confint(SATM_orig)
SATM_bootstrap<- do(5000) * coef(lm(GPA~SATM*HSGPA, data=resample(FirstYearGPA)))
glimpse(SATM_bootstrap)
qplot(x=SATM.HSGPA, data=SATM_bootstrap)
zs <- qnorm(c(0.025, 0.975))
coef(SATM_orig)["SATM:HSGPA"] + zs * sd(~SATM.HSGPA, data=SATM_bootstrap)
qdata(~SATM.HSGPA, p=c(0.025, 0.975), data=SATM_bootstrap)
View(FirstYearGPA)
# Bootstrap to generate sampling distribution of interaction coefficient
perch_bootstrap <- do(5000) * coef(lm(Weight~Length*Width, data=resample(Perch)))
glimpse(perch_bootstrap)
qplot(x=Length*Width, data=perch_bootstrap)
perch_orig <- lm(Weight ~ Length + Width + Length*Width, data = Perch)
summary(perch_orig)
confint(perch_orig)
# Bootstrap to generate sampling distribution of interaction coefficient
perch_bootstrap <- do(5000) * coef(lm(Weight~Length*Width, data=resample(Perch)))
glimpse(perch_bootstrap)
qplot(x=perch.Length*Width, data=perch_bootstrap)
# Method 1: Standard Deviation
zs <- qnorm(c(0.025, 0.975))
coef(perch_orig)["perch:Length*Width"] + zs * sd(~perch.Length*Width, data=perch_bootstrap)
qdata(~perch.Length*Width, p=c(0.025, 0.975), data=perch_bootstrap)
qs <- qdata(~perch.Length*Width, p = c(0.025, 0.975), data=perch_bootstrap)$quantile
coef(perch_orig)["perch:Length*Width"] - (qs - coef(perch_orig)["perch:Length*Width"])
perch_orig <- lm(Weight ~ Length + Width + Length*Width, data = Perch)
summary(perch_orig)
confint(perch_orig)
# Bootstrap to generate sampling distribution of interaction coefficient
perch_bootstrap <- do(5000) * coef(lm(Weight~Length*Width, data=resample(Perch)))
glimpse(perch_bootstrap)
qplot(x=Length*Width, data=perch_bootstrap)
# Method 1: Standard Deviation
zs <- qnorm(c(0.025, 0.975))
coef(perch_orig)["perch:Length*Width"] + zs * sd(~Length*Width, data=perch_bootstrap)
qdata(~Length*Width, p=c(0.025, 0.975), data=perch_bootstrap)
qs <- qdata(~Length*Width, p = c(0.025, 0.975), data=perch_bootstrap)$quantile
coef(perch_orig)["perch:Length*Width"] - (qs - coef(perch_orig)["perch:Length*Width"])
zs <- qnorm(c(0.025, 0.975))
coef(SATM_orig)["SATM:HSGPA"] + zs * sd(~SATM.HSGPA, data=SATM_bootstrap)
s <- qnorm(c(0.025, 0.975))
coef(perch_orig)["perch:Length*Width"] + zs * sd(~perch.Length*Width, data=perch_bootstrap)
zs <- qnorm(c(0.025, 0.975))
coef(perch_orig)["perch:Length*Width"] + zs * sd(~Length*Width, data=perch_bootstrap)
zs <- qnorm(c(0.025, 0.975))
coef(perch_orig)["Weight:Length*Width"] + zs * sd(~Length*Width, data=perch_bootstrap)
perch_orig <- lm(Weight ~ Length + Width + Length*Width, data = Perch)
summary(perch_orig)
confint(perch_orig)
# Bootstrap to generate sampling distribution of interaction coefficient
perch_bootstrap <- do(5000) * coef(lm(Weight~Length*Width, data=resample(Perch)))
glimpse(perch_bootstrap)
qplot(x=Length.Width, data=perch_bootstrap)
# Method 1: Standard Deviation
zs <- qnorm(c(0.025, 0.975))
coef(perch_orig)["Length:Width"] + zs * sd(~Length.Width, data=perch_bootstrap)
# Method 2: Quantiles from the Bootstrap Distribution
qdata(~Length.Width, p=c(0.025, 0.975), data=perch_bootstrap)
# Method 3: Reverse the Quantiles from the Bootstrap Distribution
qs <- qdata(~Length.Width, p = c(0.025, 0.975), data=perch_bootstrap)$quantile
coef(perch_orig)["Length:Width"] - (qs - coef(perch_orig)["Length:Width"])
blogdown:::new_post_addin()
?xyplot
plot(infantwb$num_wake~infantwb$bed_type)
# Infant WaterBed CB[1]
num_wake <- c(0.89, 0.77, 0.00, 0.65, 0.88, 1.36, 1.22, 0.30, 1.36, 1.66, 0.11, 1.44, 1.63, 1.52, 1.53, 0.48)
bed_type <- c(1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2)
babies <- c(1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8)
infantwb <- data.frame(num_wake, bed_type, babies)
str(infantwb)
# check group means and standard deviations
tapply(infantwb$num_wake,infantwb$bed_type,mean)
tapply(infantwb$num_wake,infantwb$bed_type,sd)
tapply(infantwb$num_wake,infantwb$babies,mean)
tapply(infantwb$num_wake,infantwb$babies,sd)
plot(infantwb$num_wake~infantwb$bed_type)
# Infant WaterBed CB[1]
num_wake <- c(0.89, 0.77, 0.00, 0.65, 0.88, 1.36, 1.22, 0.30, 1.36, 1.66, 0.11, 1.44, 1.63, 1.52, 1.53, 0.48)
bed_type <- c(1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2)
babies <- c(1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8)
infantwb <- data.frame(num_wake, bed_type, babies)
str(infantwb)
# check group means and standard deviations
tapply(infantwb$num_wake,infantwb$bed_type,mean)
tapply(infantwb$num_wake,infantwb$bed_type,sd)
tapply(infantwb$num_wake,infantwb$babies,mean)
tapply(infantwb$num_wake,infantwb$babies,sd)
xyplot(infantwb$num_wake~infantwb$bed_type)
?xyplot
library(lattice)
library(lattice)
# Infant WaterBed CB[1]
num_wake <- c(0.89, 0.77, 0.00, 0.65, 0.88, 1.36, 1.22, 0.30, 1.36, 1.66, 0.11, 1.44, 1.63, 1.52, 1.53, 0.48)
bed_type <- c(1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2)
babies <- c(1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8)
infantwb <- data.frame(num_wake, bed_type, babies)
str(infantwb)
# check group means and standard deviations
tapply(infantwb$num_wake,infantwb$bed_type,mean)
tapply(infantwb$num_wake,infantwb$bed_type,sd)
tapply(infantwb$num_wake,infantwb$babies,mean)
tapply(infantwb$num_wake,infantwb$babies,sd)
xyplot(infantwb$num_wake~infantwb$bed_type)
boxplot(infantwb$num_wake~infantwb$bed_type)
